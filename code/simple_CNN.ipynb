{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import CSVLogger,ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nnum_classes = 67\nepochs = 30\ninput_shape = (28, 28, 1)\ndatagen = ImageDataGenerator(\n        rescale=1.0/255.0,\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False,\n        validation_split=0.2) # randomly flip images\ntrain_generator = datagen.flow_from_directory(\n    directory=r\"/kaggle/input/extracted_data_train_test/extracted_data_train_test/train_imgs2/\",\n    target_size=(28, 28),\n    color_mode=\"grayscale\",\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\nvalidation_generator = datagen.flow_from_directory(\n    directory=r\"/kaggle/input/extracted_data_train_test/extracted_data_train_test/train_imgs2/\", # same directory as training data\n    target_size=(28, 28),\n    color_mode=\"grayscale\",\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True,\n    seed=42,\n    subset='validation')\nx_train, y_train = next(train_generator)\nprint(x_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.20))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Architencture2\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(67, activation = \"softmax\"))\noptimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1.0/255.0)\ntest_generator = test_datagen.flow_from_directory(\n    target_size=(28, 28),\n    batch_size = 64,\n    color_mode=\"grayscale\",\n    shuffle = False,\n    directory=r\"/kaggle/input/extracted_data_train_test/extracted_data_train_test/\",\n    classes=['test_imgs2'])\nprint(len(test_generator.filenames))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_steps_per_epoch = 22557 // batch_size\n#28160  // batch_size\nval_steps_per_epoch = 5603 // batch_size\nMODEL_FILE = 'simple_cnn_model_final'\nfilepath = \"simple_cnn_adam-{epoch:02d}\"\ncsv_logger = CSVLogger('cnn_log.csv', append = True, separator = ',')\ncheckpointer = ModelCheckpoint(filepath, monitor = 'acc', verbose = 1, save_best_only = False, save_weights_only = False, \n                               mode = 'max',period = 1)\n\nmodel.fit_generator(\n    train_generator,\n    epochs=epochs,\n    steps_per_epoch=train_steps_per_epoch,\n    validation_data=validation_generator,\n    validation_steps=val_steps_per_epoch,\n    callbacks =[csv_logger,checkpointer,learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\ntest_generator.reset()\n#eval_var= model.evaluate_generator(generator=validation_generator,\n#steps=val_steps_per_epoch, verbose = 1)\n#STEP_SIZE_TEST=9691//1\ntest_generator.reset()\npred2=model.predict_generator(test_generator,\nsteps = 9691/batch_size,\nverbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(pred2))\npredicted_class_indices=np.argmax(pred2,axis=1)\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\nfilenames=test_generator.filenames\nprint(len(filenames))\nprint(len(predictions))\nresults3=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\nresults3.to_csv(\"full_data_results.csv\",index=False)\nprint('All Done!')\nresults3.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(os.getcwd()))\nprint(os.getcwd())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"results_Adam.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_download_link(results3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}